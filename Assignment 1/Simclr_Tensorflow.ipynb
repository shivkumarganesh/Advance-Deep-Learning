{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simclr-Tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWNWeULaeSh+z8SLFphDjF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivkumarganesh/Advance-Deep-Learning/blob/main/Assignment%201/Simclr_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-iqXCQThYW4",
        "outputId": "3cb5b419-b1c6-43e9-8eff-3bb437f61e49"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzsQSnE9h1pq"
      },
      "source": [
        "# Other imports\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Random seed fixation\n",
        "tf.random.set_seed(666)\n",
        "np.random.seed(666)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH7KXvpniDEy",
        "outputId": "b48e4dfe-19c6-4faf-cfbf-fcff19185d09"
      },
      "source": [
        "# Gather dataset\n",
        "!git clone https://github.com/thunderInfy/imagenet-5-categories"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'imagenet-5-categories' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPGl46jEiDg0",
        "outputId": "9574ef1f-e56b-4743-f7d9-37d1cc6c6004"
      },
      "source": [
        "# How many training images for SimCLR?\n",
        "train_images = list(paths.list_images(\"imagenet-5-categories/train\"))\n",
        "print(len(train_images))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o2bec4EiFfF"
      },
      "source": [
        "# Augmentation utilities (differs from the original implementation)\n",
        "# Referred from: https://arxiv.org/pdf/2002.05709.pdf (Appendxi A \n",
        "# corresponding GitHub: https://github.com/google-research/simclr/)\n",
        "\n",
        "class CustomAugment(object):\n",
        "    def __call__(self, sample):        \n",
        "        # Random flips\n",
        "        sample = self._random_apply(tf.image.flip_left_right, sample, p=0.5)\n",
        "        \n",
        "        # Randomly apply transformation (color distortions) with probability p.\n",
        "        sample = self._random_apply(self._color_jitter, sample, p=0.8)\n",
        "        sample = self._random_apply(self._color_drop, sample, p=0.2)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def _color_jitter(self, x, s=1):\n",
        "        # one can also shuffle the order of following augmentations\n",
        "        # each time they are applied.\n",
        "        x = tf.image.random_brightness(x, max_delta=0.8*s)\n",
        "        x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "        x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "        x = tf.clip_by_value(x, 0, 1)\n",
        "        return x\n",
        "    \n",
        "    def _color_drop(self, x):\n",
        "        x = tf.image.rgb_to_grayscale(x)\n",
        "        x = tf.tile(x, [1, 1, 1, 3])\n",
        "        return x\n",
        "    \n",
        "    def _random_apply(self, func, x, p):\n",
        "        return tf.cond(\n",
        "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                  tf.cast(p, tf.float32)),\n",
        "          lambda: func(x),\n",
        "          lambda: x)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMiKLvWKiIsK"
      },
      "source": [
        "# Build the augmentation pipeline\n",
        "data_augmentation = Sequential([Lambda(CustomAugment())])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvvb4uRQiMhn"
      },
      "source": [
        "\n",
        "# Image preprocessing utils\n",
        "@tf.function\n",
        "def parse_images(image_path):\n",
        "    image_string = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, size=[224, 224])\n",
        "\n",
        "    return image"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ6tpWCUiO5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c49b2911-64ad-4965-b1b4-f87041a38c1f"
      },
      "source": [
        "# Create TensorFlow dataset\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices(train_images)\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .map(parse_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .shuffle(1024)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKYtrrDAiTj-"
      },
      "source": [
        "# Architecture utils\n",
        "def get_resnet_simclr(hidden_1, hidden_2, hidden_3):\n",
        "    base_model = tf.keras.applications.ResNet50(include_top=False, weights=None, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = True\n",
        "    inputs = Input((224, 224, 3))\n",
        "    h = base_model(inputs, training=True)\n",
        "    h = GlobalAveragePooling2D()(h)\n",
        "\n",
        "    projection_1 = Dense(hidden_1)(h)\n",
        "    projection_1 = Activation(\"relu\")(projection_1)\n",
        "    projection_2 = Dense(hidden_2)(projection_1)\n",
        "    projection_2 = Activation(\"relu\")(projection_2)\n",
        "    projection_3 = Dense(hidden_3)(projection_2)\n",
        "\n",
        "    resnet_simclr = Model(inputs, projection_3)\n",
        "\n",
        "    return resnet_simclr"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLD6gNgFiYaq",
        "outputId": "151cf25a-d912-4f65-f062-e97c41edb9fe"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/helpers.py\n",
        "!wget https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/losses.py"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-25 05:37:11--  https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/helpers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 891 [text/plain]\n",
            "Saving to: ‘helpers.py.1’\n",
            "\n",
            "\rhelpers.py.1          0%[                    ]       0  --.-KB/s               \rhelpers.py.1        100%[===================>]     891  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-25 05:37:11 (35.6 MB/s) - ‘helpers.py.1’ saved [891/891]\n",
            "\n",
            "--2021-09-25 05:37:11--  https://raw.githubusercontent.com/sthalles/SimCLR-tensorflow/master/utils/losses.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 891 [text/plain]\n",
            "Saving to: ‘losses.py.1’\n",
            "\n",
            "losses.py.1         100%[===================>]     891  --.-KB/s    in 0s      \n",
            "\n",
            "2021-09-25 05:37:11 (39.7 MB/s) - ‘losses.py.1’ saved [891/891]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSvqvT4RiqAq"
      },
      "source": [
        "from losses import _dot_simililarity_dim1 as sim_func_dim1, _dot_simililarity_dim2 as sim_func_dim2\n",
        "\n",
        "def get_negative_mask(batch_size):\n",
        "    # return a mask that removes the similarity score of equal/similar images.\n",
        "    # this function ensures that only distinct pair of images get their similarity scores\n",
        "    # passed as negative examples\n",
        "    negative_mask = np.ones((batch_size, 2 * batch_size), dtype=bool)\n",
        "    for i in range(batch_size):\n",
        "        negative_mask[i, i] = 0\n",
        "        negative_mask[i, i + batch_size] = 0\n",
        "    return tf.constant(negative_mask)\n",
        "\n",
        "\n",
        "def gaussian_filter(v1, v2):\n",
        "    k_size = int(v1.shape[1] * 0.1)  # kernel size is set to be 10% of the image height/width\n",
        "    gaussian_ope = GaussianBlur(kernel_size=k_size, min=0.1, max=2.0)\n",
        "    [v1, ] = tf.py_function(gaussian_ope, [v1], [tf.float32])\n",
        "    [v2, ] = tf.py_function(gaussian_ope, [v2], [tf.float32])\n",
        "    return v1, v2\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "476GFNhGis3R"
      },
      "source": [
        "@tf.function\n",
        "def train_step(xis, xjs, model, optimizer, criterion, temperature):\n",
        "    with tf.GradientTape() as tape:\n",
        "        zis = model(xis)\n",
        "        zjs = model(xjs)\n",
        "\n",
        "        # normalize projection feature vectors\n",
        "        zis = tf.math.l2_normalize(zis, axis=1)\n",
        "        zjs = tf.math.l2_normalize(zjs, axis=1)\n",
        "\n",
        "        l_pos = sim_func_dim1(zis, zjs)\n",
        "        l_pos = tf.reshape(l_pos, (BATCH_SIZE, 1))\n",
        "        l_pos /= temperature\n",
        "\n",
        "        negatives = tf.concat([zjs, zis], axis=0)\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        for positives in [zis, zjs]:\n",
        "            l_neg = sim_func_dim2(positives, negatives)\n",
        "\n",
        "            labels = tf.zeros(BATCH_SIZE, dtype=tf.int32)\n",
        "\n",
        "            l_neg = tf.boolean_mask(l_neg, get_negative_mask(BATCH_SIZE))\n",
        "            l_neg = tf.reshape(l_neg, (BATCH_SIZE, -1))\n",
        "            l_neg /= temperature\n",
        "\n",
        "            logits = tf.concat([l_pos, l_neg], axis=1) \n",
        "            loss += criterion(y_pred=logits, y_true=labels)\n",
        "\n",
        "        loss = loss / (2 * BATCH_SIZE)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLbUmlD2jCsx"
      },
      "source": [
        "def train_simclr(model, dataset, optimizer, criterion,temperature=0.1, epochs=100):\n",
        "  step_wise_loss = []\n",
        "  epoch_wise_loss = []\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    for image_batch in dataset:\n",
        "        a = data_augmentation(image_batch)\n",
        "        b = data_augmentation(image_batch)\n",
        "\n",
        "        loss = train_step(a, b, model, optimizer, criterion, temperature)\n",
        "        step_wise_loss.append(loss)\n",
        "\n",
        "    epoch_wise_loss.append(np.mean(step_wise_loss))\n",
        "    if epoch % 10 == 0:\n",
        "      print(\"epoch: {} loss: {:.3f}\".format(epoch + 1, np.mean(step_wise_loss)))\n",
        "\n",
        "  return epoch_wise_loss, model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMvCSiJWjaW4",
        "outputId": "6298695c-ef44-4ff9-b25d-68ce40f1d55b"
      },
      "source": [
        "criterion = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
        "decay_steps = 1000\n",
        "lr_decayed_fn = tf.keras.experimental.CosineDecay(initial_learning_rate=0.1, decay_steps=decay_steps)\n",
        "optimizer = tf.keras.optimizers.SGD(lr_decayed_fn)\n",
        "\n",
        "resnet_simclr_2 = get_resnet_simclr(256, 128, 50)\n",
        "\n",
        "epoch_wise_loss, resnet_simclr  = train_simclr(resnet_simclr_2, train_ds, optimizer, criterion, temperature=0.1, epochs=200)\n",
        "\n",
        "with plt.xkcd():\n",
        "    plt.plot(epoch_wise_loss)\n",
        "    plt.title(\"tau = 0.1, h1 = 256, h2 = 128, h3 = 50\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/200 [01:26<4:46:17, 86.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: 2.397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jRWAiusjf2L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}